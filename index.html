<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Xinge Yang</title>

  <meta name="author" content="Xinge Yang">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon"
    href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">


          <!-- Introduction ------------------------------------------------------------ -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center; font-size:10px;">
                    <name>Xinge Yang (Êù®ËæõÊ†º)</name>
                  </p>

                  <p>
                    I am a Ph.D. candidate at KAUST Computational Imaging Group, working with Prof. <a
                      href="https://vccimaging.org/People/heidriw/">Wolfgang Heidrich</a>. My research focuses on
                    <b>differentiable optical design</b> and <b>end-to-end imaging simulation</b>. I explore the next generation computational cameras for mobile phones and smart glasses, from hardware design and computer vision.</b>
                  </p>

                  <p>
                    My representative work published in <a href="https://www.nature.com/articles/s41467-024-50835-7">Nature Communications</a> enables automated optical design. Based on this work, I maintain an open-source differentiable optical simulator <a href="https://github.com/singer-yang/DeepLens">DeepLens</a>, which enables end-to-end 
                    optimization for optics, sensor, and neural network. DeepLens has a growing community with hundreds of users. Feel free to drop me an email if you are also interested!
                  </p>

                  <p style="text-align:center">
                    <a href="mailto:xinge.yang@kaust.edu.sa">Email</a> &nbsp/&nbsp
                    <a href="https://scholar.google.com/citations?hl=en&user=3kiUwS0AAAAJ">Google Scholar</a>
                    &nbsp/&nbsp
                    <a href="https://github.com/singer-yang/">Github</a> &nbsp/&nbsp
                    <a href="https://www.linkedin.com/in/xinge-yang-16152b190/">LinkedIn</a> &nbsp/&nbsp
                    <a href="https://www.zhihu.com/people/yxg-21">Áü•‰πé</a>
                  </p>

                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/xingeyang_square.jpg"><img style="width:100%;max-width:100%" alt="profile photo"
                      src="images/xingeyang_circle.jpg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <!-- Introduction ------------------------------------------------------------ -->


          <!-- News ------------------------------------------------------------ -->
          <!-- <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>News</heading>
                  <p>
                    <li>11/2024: I will attend Siggraph Asia this year, see you in Tokyo.</li>
                    <li>08/2024: <b>"Curriculum Learning for ab initio Deep Learned Refractive Optics"</b> is acceptted
                      by <b>
                        <font color="1772d0">Nature Communications</font>
                      </b>!</li>
                    <li>03/2024: <a href="https://github.com/singer-yang/DeepLens">DeepLens</a> is open-sourced, build
                      your End-to-End lens design pipeline with 5 lines of Python code!</li>
                    <li>10/2023: I started my internship at Meta, working on gradient-based optical design for AR
                      waveguide.</li>
                    <li>09/2023: We released an automated lens design demo <a
                        href="https://github.com/singer-yang/AutoLens">AutoLens </a>. </li>
                    <li>07/2023: Our paper, <b>"Aberration-Aware Depth-from-Focus"</b> is accepted by <b>
                        <font color="1772d0">ICCP</font>
                      </b> and <b>
                        <font color="1772d0">TPAMI</font>
                      </b>.</li> -->
                    <!-- <li>05/2023: Our paper <b>"Image Quality Is Not All You Want: Task-Driven Lens Design for Image Classification"</b> is avaliable on <a href="https://arxiv.org/abs/2305.17185">Arxiv</a>. </li> -->
                    <!-- <li>05/2023: I will attend Siggraph this year, see you in LA!</li> -->
                    <!-- <li><del>21/03/2023: I will attend CVPR this year, see you in Vancouver!</del></li> -->
                    <!-- <li>09/03/2023: Our paper, <b>"Aberration-Aware Depth-from-Focus"</b> is avaliable on Arxiv. <a href="https://arxiv.org/abs/2303.04654">paper link</a>.</li> -->
                    <!-- <li>02/2023: The DeepLens paper, <b>"Curriculum Learning for ab initio Deep Learned Refractive Optics"</b> is avaliable on Arxiv. <a href="https://arxiv.org/abs/2302.01089">paper link</a>.</li> -->
                    <!-- <li>01/2023: Happy new year! Please have a look at <a href="https://github.com/singer-yang/awesome-deep-optics">"awesome-deep-optics" </a> repo if you are intested in optics and network co-design. </li> -->
                    <!-- <li>06/2022: I will give a presentation at COSI conference about our automatic lens design project. Time: 14:15-14:30, Pacific Time, UTC -7:00. Location: Hyatt Regency Vancouver.</li> -->
                    <!-- <li>05/2022: Our paper <b>"Automatic Lens Design based on Differentiable Ray-tracing"</b> is accepted by OSA Imaging Congress - COSI, see you in Vancouver!</li> -->
                    <!-- <li>04/2022: I got the opportunity from my advisor to attend Siggraph this year, see you in Vancouvar!</li> -->
                    <!-- <li>03/2022: I defended my Master thesis <b>"Automatic Lens Design based on Differentiable Ray-tracing"</b>! </li> -->
                    <!-- <li>09/2020: I started Master program at KAUST!</li> -->
                  <!-- </p>
                </td>
              </tr>
            </tbody>
          </table> -->
          <!-- News ------------------------------------------------------------ -->


          <!-- Education ------------------------------------------------------------ -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Education</heading>
                  <p>
                    <li style="padding-bottom:5px">2022 - 2026 (expected): Ph.D. in Computer Science, KAUST, Saudi Arabia.
                    </li>
                    <li style="padding-bottom:5px">2020 - 2022: M.Sc. in Computer Science, KAUST, Saudi Arabia.</li>
                    <li style="padding-bottom:5px">2016 - 2020: B.Sc. in Physics (major) and Computer Science (minor),
                      USTC, China.</li>
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <!-- Education ------------------------------------------------------------ -->


          <!-- Working ------------------------------------------------------------ -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Working</heading>
                  <p>
                    <li style="padding-bottom:5px">07/2024 - 11/2024: Research scientist Intern, XR Tech Camera &
                      Sensing, Meta Reality Labs, Sunnyvale, CA, USA.</li>
                    <li style="padding-bottom:5px">10/2023 - 01/2024: Research scientist Intern, Optics & Display
                      Research, Meta Reality Labs Research, Redmond, WA, USA</li>
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <!-- Working ------------------------------------------------------------ -->

          <!-- Research ------------------------------------------------------------ -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding-left:20px;padding-top:20px;padding-right:20px;width:100%;vertical-align:middle">
                  <heading>Research</heading>
                  <p>
                    My research focuses on two topics:
                    <li>Differentiable optical design</li>
                    <li>End-to-end imaging simulation</li>
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <!-- Research ------------------------------------------------------------ -->

          <!-- Publications ------------------------------------------------------------ -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              
              <!-- Header for first author papers-->
              <tr>
                <td style="padding-left:20px">
                  <p>First author papers:</p>
                </td>
              </tr>

              <!-- ============================================================================== -->
              <tr onmouseout="defocusdeblur_stop()" onmouseover="defocusdeblur_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='defocusdeblur'><img src='images/defocusdeblur_2.jpg'></div>
                    <img src='images/defocusdeblur_1.jpg'>
                  </div>
                  <script type="text/javascript">
                    function defocusdeblur_start() {
                      document.getElementById('defocusdeblur').style.opacity = "1";
                    }
                    function defocusdeblur_stop() {
                      document.getElementById('defocusdeblur').style.opacity = "0";
                    }
                    defocusdeblur_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2507.00372">
                    <papertitle>Efficient Depth- and Spatially-Varying Image Simulation for Defocus Deblur
                    </papertitle>
                  </a>
                  <br>
                  <b>Xinge Yang</b>, Chuong Nguyen, Wenbin Wang, Kaizhang Kang, Wolfgang Heidrich, Ginger Li
                  <br>
                  <em>ICCV Workshop 2025.</b>
                  <a href="https://arxiv.org/abs/2507.00372">Paper (Arxiv)</a> / <a href="#">Paper (PDF, coming soon)</a> / <a href="#">Supp (PDF, coming soon)</a></em>
                  <br>
                  <p></p>
                  <p>
                    <li>Efficient and practical synthetic dataset validated by real cameras.</li>
                  </p>
                </td>
              </tr>

              <!-- ============================================================================== -->
              <tr onmouseout="hybridlens_stop()" onmouseover="hybridlens_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='hybridlens'><img src='images/hybridlens2.jpg'></div>
                    <img src='images/hybridlens1.jpg'>
                  </div>
                  <script type="text/javascript">
                    function hybridlens_start() {
                      document.getElementById('hybridlens').style.opacity = "1";
                    }
                    function hybridlens_stop() {
                      document.getElementById('hybridlens').style.opacity = "0";
                    }
                    hybridlens_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2406.00834">
                    <papertitle>End-to-End Hybrid Refractive-Diffractive Lens Design with Differentiable Ray-Wave Model
                    </papertitle>
                  </a>
                  <br>
                  <b>Xinge Yang</b>, <a href="https://matheusvms.github.io/">Matheus Souza</a>, <a
                    href="https://scholar.google.com/citations?user=D4xDAlUAAAAJ&hl=en">Kunyi Wang</a>, <a
                    href="https://www.cs.unc.edu/~cpk/">Praneeth Chakravarthula</a>, <a
                    href="https://vccimaging.org/People/fuq/">Qiang Fu</a>, <a
                    href="https://vccimaging.org/People/heidriw/">Wolfgang Heidrich</a>
                  <br>
                  <em>Siggraph Asia 2024.</b> <a href="https://arxiv.org/abs/2406.00834">Paper (Arxiv)</a> / <a
                      href="papers/HybridLens.pdf">Paper (PDF)</a> / <a href="papers/HybridLens_supp.pdf">Supp
                      (PDF)</a></em>
                  <br>
                  <p></p>
                  <p>
                    <li>Differentiable ray-tracing and wave-propagation model.</li>
                    <li>End-to-End hybrid refractive-diffractive lenses design with prototypes.</li>
                  </p>
                </td>
              </tr>


              <!-- ============================================================================== -->
              <tr onmouseout="tasklens_stop()" onmouseover="tasklens_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='tasklens'><img src='images/tasklens2.png'></div>
                    <img src='images/tasklens1.png'>
                  </div>
                  <script type="text/javascript">
                    function tasklens_start() {
                      document.getElementById('tasklens').style.opacity = "1";
                    }

                    function tasklens_stop() {
                      document.getElementById('tasklens').style.opacity = "0";
                    }
                    tasklens_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2305.17185">
                    <papertitle>Image Quality Is Not All You Want: Task-Driven Lens Design for Image
                      Classification</papertitle>
                  </a>
                  <br>
                  <b>Xinge Yang</b>, <a href="https://vccimaging.org/People/fuq/">Qiang Fu</a>, <a
                    href="https://www.b-phot.org/team/yunfeng-nie">Yunfeng Nie</a>, <a
                    href="https://vccimaging.org/People/heidriw/">Wolfgang Heidrich</a>
                  <br>
                  <em>Arxiv prepint.</b> <a href="https://arxiv.org/abs/2305.17185">Paper (Arxiv)</a> / <a
                      href="papers/TaskLens.pdf">Paper (PDF)</a> / <a href="papers/TaskLens_supp.pdf">Supp
                      (PDF)</a></em>
                  <br>
                  <p></p>
                  <p>
                    <li>A new End-to-End optical design methedology: a well-trained network as objective.</li>
                    <li>TaskLens: better computer vision performance with fewer lens elements.
                  </p>
                </td>
              </tr>


              <!-- ============================================================================== -->
              <tr onmouseout="aat_dff_stop()" onmouseover="aat_dff_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='aat_dff'><img src='images/aat_dff1.png'></div>
                    <img src='images/aat_dff2.png'>
                  </div>
                  <script type="text/javascript">
                    function aat_dff_start() {
                      document.getElementById('aat_dff').style.opacity = "1";
                    }

                    function aat_dff_stop() {
                      document.getElementById('aat_dff').style.opacity = "0";
                    }
                    aat_dff_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2303.04654">
                    <papertitle>Aberration-Aware Depth-from-Focus</papertitle>
                  </a>
                  <br>
                  <b>Xinge Yang</b>, <a href="https://vccimaging.org/People/fuq/">Qiang Fu</a>, <a
                    href="http://www.mohamed-elhoseiny.com/">Mohamed Elhoseiny</a>, <a
                    href="https://vccimaging.org/People/heidriw/">Wolfgang Heidrich</a>
                  <br>
                  <em>TPAMI & ICCP 2023.</b> <a href='https://ieeexplore.ieee.org/document/10209238'>Paper (IEEE)</a> /
                    <a href='papers/AberAwareDfF.pdf'>Paper (PDF)</a> / <a href='papers/AberAwareDfF_supp.pdf'>Supp
                      (PDF)</a> / <a href=https://vccimaging.org/Publications/Yang2023AATDfF>Project page</a> / <a
                      href=https://github.com/singer-yang/Aberration-Aware-Depth-from-Focus>Code</a></em>
                  <br>
                  <p></p>
                  <p>
                    <li>An implicite network for real-lens spatially-varying focus-dependent (4D) PSFs representation.
                    </li>
                    <li>Generalize depth-from-focus network from synthetic data to real data by considering optical
                      aberrations.
                  </p>
                </td>
              </tr>


              <!-- ============================================================================== -->
              <tr onmouseout="deeplens_stop()" onmouseover="deeplens_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='deeplens'><img src='images/deeplens2.jpg'></div>
                    <img src='images/deeplens1.jpg'>
                  </div>
                  <script type="text/javascript">
                    function deeplens_start() {
                      document.getElementById('deeplens').style.opacity = "1";
                    }
                    function deeplens_stop() {
                      document.getElementById('deeplens').style.opacity = "0";
                    }
                    deeplens_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2302.01089">
                    <papertitle>Curriculum Learning for ab initio Deep Learned Refractive Optics</papertitle>
                  </a>
                  <br>
                  <b>Xinge Yang</b>, <a href="https://vccimaging.org/People/fuq/">Qiang Fu</a>, <a
                    href="https://vccimaging.org/People/heidriw/">Wolfgang Heidrich</a>
                  <br>
                  <em>Nature Communications 2024.</b> <a href="https://www.nature.com/articles/s41467-024-50835-7">Paper
                      (Nature)</a> / <a href='papers/DeepLens.pdf'>Paper (PDF)</a> / <a
                      href='papers/DeepLens_supp.pdf'>Supp (PDF)</a> / <a
                      href=https://github.com/singer-yang/DeepLens>Code</a> / <a
                      href=https://youtu.be/32XuSyM-J-8>Video</a></em>
                  <br>
                  <!-- <em>OSA Imaging and Applid Optics Congress - Computational Optical Sensing and Imaging (COSI) 2022 (oral): <a href=https://opg.optica.org/abstract.cfm?uri=COSI-2022-CTh4C.2>paper</a>, <a href=https://vccimaging.org/Publications/Yang2022AutoLens/>project</a>, <a href=https://github.com/singer-yang/AutoLens>code</a></em> -->
                  <!-- <br> -->
                  <p></p>
                  <p>
                    <li>Automated lens design from scratch with differentiable ray tracing.</li>
                    <li>DeepLens framework for (1) differentiable ray tracing simulation, (2) end-to-end lens-network
                      co-design.</li>
                  </p>
                </td>
              </tr>

              <!-- Header for co-author papers -->
              <tr>
                <td style="padding-left:20px">
                  <p>Co-author papers:</p>
                </td>
              </tr>

              <!-- ============================================================================== -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/tolerance_lens.jpg'>
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2502.04719">
                    <papertitle>Tolerance-Aware Deep Optics</papertitle>
                  </a>
                  <br>
                  Jun Dai, Liqun Chen, <b>Xinge Yang</b>, Yuyao Hu, Jinwei Gu, Tianfan Xue
                  <br>
                  <em>Arxiv prepint 2025.
                    <a href="https://arxiv.org/abs/2502.04719">Paper (Arxiv)</a>
                    <a href="https://openimaginglab.github.io/LensTolerance/">Project page</a>
                  </em>
                  <br>
                  <p></p>
                  <p>
                    <li>Considering lens manufacturing tolerances in end-to-end lens design.</li>
                  </p>
                </td>
              </tr>

              <!-- ============================================================================== -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/fluidic_lens.jpg'>
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2406.00834">
                    <papertitle>End-to-end Optimization of Fluidic Lenses</papertitle>
                  </a>
                  <br>
                  Mulun Na, Hector Jimenez-Romero, <b>Xinge Yang</b>, Jonathan Klein, Dominik L. Michels, Wolfgang
                  Heidrich
                  <br>
                  <em>Siggraph Asia 2024.
                    <a href="https://computationalsciences.org/publications/na-2024-fluidic-lenses/na-2024-fluidic-lenses.pdf">Paper (PDF)</a>, 
                    <a href="https://computationalsciences.org/publications/na-2024-fluidic-lenses.html">Project page</a>
                  </em>
                  <br>
                  <p></p>
                  <p>
                    <li>Differentiable edge shape defined lens surface optimization.</li>
                    <li>Fast prototyping with fluidic manufacturing.</li>
                  </p>
                </td>
              </tr>

            </tbody>
          </table>

          <!-- Miscs ------------------------------------------------------------ -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Miscs</heading>
                  <p>
                    <li><b>More about me:</b> I like cats, photography, new techs, and most sports (especially
                      basketball and water sports). I lived in China, Singapore, Saudi Arabia, and the US, and want
                      to live in different places to experience the lifestyle of local people. I enjoy adventures
                      and challenges. I love my life.</li>
                    <br>
                    <li><b>Peer review statement:</b> I am pleased to be invited for peer review in my research
                      field. I will try my best to complete the review within two weeks. I apply the same high
                      standards to every paper, aiming for the utmost potential of the topic. However, I do not
                      expect the authors to address every suggestion I make and leave the final judgment to the
                      associate editor.</li>
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <!-- Miscs ------------------------------------------------------------ -->

          <!-- Footer ------------------------------------------------------------ -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:right;font-size:small;">
                    The website template is from <a href="https://jonbarron.info/">Dr. John Barron</a>.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <!-- Footer ------------------------------------------------------------ -->

        </td>
      </tr>
    </tbody>
  </table>
</body>

</html>