<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Xinge Yang</title>

  <meta name="author" content="Xinge Yang">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon"
    href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">


          <!-- Introduction ------------------------------------------------------------ -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center; font-size:10px;">
                    <name>Xinge Yang (Êù®ËæõÊ†º)</name>
                  </p>

                  <p>
                    I am a Ph.D. candidate at KAUST Computational Imaging Group, working with Prof. <a href="https://vccimaging.org/People/heidriw/">Wolfgang Heidrich</a>. My research focuses on <b>differentiable optical design</b> and <b>end-to-end imaging simulation</b>. I explore the next generation computational cameras, sensing systems, and AR/VR glasses.</b>
                  </p>

                  <p>
                    My representative work published in <a href="https://www.nature.com/articles/s41467-024-50835-7">Nature Communications</a> enables automated optical design. Based on this work, I maintain an open-source differentiable optical lens simulator <a href="https://github.com/singer-yang/DeepLens">DeepLens</a> for end-to-end simulation and optimization of optics, sensor, and computer vision.
                  </p>

                  <p class="job-market">
                    I am now on the job market for 2026 full-time positions. Please feel free to contact me if you are interested in my research.
                  </p>

                  <p style="text-align:center">
                    <a href="mailto:xinge.yang@kaust.edu.sa">Email</a> &nbsp/&nbsp
                    <a href="https://scholar.google.com/citations?hl=en&user=3kiUwS0AAAAJ">Google Scholar</a>
                    &nbsp/&nbsp
                    <a href="https://github.com/singer-yang/">Github</a> &nbsp/&nbsp
                    <a href="https://www.linkedin.com/in/xinge-yang-16152b190/">LinkedIn</a> &nbsp/&nbsp
                    <a href="https://www.zhihu.com/people/yxg-21">Áü•‰πé</a>
                  </p>

                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/xingeyang_square.jpg"><img style="width:100%;max-width:100%" alt="profile photo"
                      src="images/xingeyang_circle.jpg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <!-- Introduction ------------------------------------------------------------ -->

          <!-- Education ------------------------------------------------------------ -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Education</heading>
                  <p>
                    <li style="padding-bottom:5px">2022 - 2026 (expected): Ph.D. in Computer Science, KAUST, Saudi Arabia.
                    </li>
                    <li style="padding-bottom:5px">2020 - 2022: M.Sc. in Computer Science, KAUST, Saudi Arabia.</li>
                    <li style="padding-bottom:5px">2016 - 2020: B.Sc. in Physics (major) and Computer Science (minor),
                      USTC, China.</li>
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <!-- Education ------------------------------------------------------------ -->


          <!-- Working ------------------------------------------------------------ -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Working</heading>
                  <p>
                    <li style="padding-bottom:5px">07/2024 - 11/2024: Research scientist Intern, XR Tech Camera &
                      Sensing, Meta Reality Labs, Sunnyvale, CA, USA.</li>
                    <li style="padding-bottom:5px">10/2023 - 01/2024: Research scientist Intern, Optics & Display
                      Research, Meta Reality Labs Research, Redmond, WA, USA</li>
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <!-- Working ------------------------------------------------------------ -->

          <!-- Research ------------------------------------------------------------ -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding-left:20px;padding-top:20px;padding-right:20px;width:100%;vertical-align:middle">
                  <heading>Research</heading>
                  <!-- <p>
                    My research focuses on two topics:
                    <li>Differentiable optical design</li>
                    <li>End-to-end imaging simulation</li>
                  </p> -->
                </td>
              </tr>
            </tbody>
          </table>
          <!-- Research ------------------------------------------------------------ -->

          <!-- Publications ------------------------------------------------------------ -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              
              <!-- Header for first author papers-->
              <tr>
                <td style="padding-left:20px">
                  <p>First author papers:</p>
                </td>
              </tr>

              <!-- ============================================================================== -->
              <tr onmouseout="diffgwg_stop()" onmouseover="diffgwg_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='diffgwg'><img src='images/diffgwg2.png'></div>
                    <img src='images/diffgwg1.png'>
                  </div>
                  <script type="text/javascript">
                    function diffgwg_start() {
                      document.getElementById('diffgwg').style.opacity = "1";
                    }
                    function defocusdeblur_stop() {
                      document.getElementById('diffgwg').style.opacity = "0";
                    }
                    diffgwg_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://www.arxiv.org/abs/2601.04370">
                    <papertitle>End-to-end differentiable design of geometric waveguide displays
                    </papertitle>
                  </a>
                  <br>
                  <b>Xinge Yang</b>, Zhaocheng Liu, Zhaoyu Nie, Qingyuan Fan, Jim Bonar, Wolfgang Heidrich
                  <br>
                  <em>arXiv prepint 2026.</b>
                  <a href="https://www.arxiv.org/abs/2601.04370">Paper (arXiv)</a> </em>
                  <br>
                  <p></p>
                  <p>
                    <li>Differentiable Monte Carlo non-sequential polarization ray tracing for geometric waveguide display coating optimization up to thousand-scale.</li>
                  </p>
                </td>
              </tr>

              <!-- ============================================================================== -->
              <tr onmouseout="defocusdeblur_stop()" onmouseover="defocusdeblur_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='defocusdeblur'><img src='images/defocusdeblur_2.jpg'></div>
                    <img src='images/defocusdeblur_1.jpg'>
                  </div>
                  <script type="text/javascript">
                    function defocusdeblur_start() {
                      document.getElementById('defocusdeblur').style.opacity = "1";
                    }
                    function defocusdeblur_stop() {
                      document.getElementById('defocusdeblur').style.opacity = "0";
                    }
                    defocusdeblur_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2507.00372">
                    <papertitle>Efficient Depth- and Spatially-Varying Image Simulation for Defocus Deblur
                    </papertitle>
                  </a>
                  <br>
                  <b>Xinge Yang</b>, Chuong Nguyen, Wenbin Wang, Kaizhang Kang, Wolfgang Heidrich, Ginger Li
                  <br>
                  <em>ICCV Workshop 2025.</b>
                  <a href="https://arxiv.org/abs/2507.00372">Paper (arXiv)</a> / <a href="./papers/EfficientDepthAndSpatiallyVaryingImageSimulationForDefocusDeblur.pdf">Paper (PDF)</a> / <a href="./papers/EfficientDepthAndSpatiallyVaryingImageSimulationForDefocusDeblur_supp.pdf">Supp (PDF)</a></em>
                  <br>
                  <p></p>
                  <p>
                    <li>Efficient high-fidelity synthetic dataset generation for camera lens defocus deblur without fine-tuning.</li>
                  </p>
                </td>
              </tr>

              <!-- ============================================================================== -->
              <tr onmouseout="hybridlens_stop()" onmouseover="hybridlens_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='hybridlens'><img src='images/hybridlens2.jpg'></div>
                    <img src='images/hybridlens1.jpg'>
                  </div>
                  <script type="text/javascript">
                    function hybridlens_start() {
                      document.getElementById('hybridlens').style.opacity = "1";
                    }
                    function hybridlens_stop() {
                      document.getElementById('hybridlens').style.opacity = "0";
                    }
                    hybridlens_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2406.00834">
                    <papertitle>End-to-End Hybrid Refractive-Diffractive Lens Design with Differentiable Ray-Wave Model
                    </papertitle>
                  </a>
                  <br>
                  <b>Xinge Yang</b>, <a href="https://matheusvms.github.io/">Matheus Souza</a>, <a
                    href="https://scholar.google.com/citations?user=D4xDAlUAAAAJ&hl=en">Kunyi Wang</a>, <a
                    href="https://www.cs.unc.edu/~cpk/">Praneeth Chakravarthula</a>, <a
                    href="https://vccimaging.org/People/fuq/">Qiang Fu</a>, <a
                    href="https://vccimaging.org/People/heidriw/">Wolfgang Heidrich</a>
                  <br>
                  <em>Siggraph Asia 2024.</b> <a href="https://arxiv.org/abs/2406.00834">Paper (arXiv)</a> / <a
                      href="papers/HybridLens.pdf">Paper (PDF)</a> / <a href="papers/HybridLens_supp.pdf">Supp
                      (PDF)</a></em>
                  <br>
                  <p></p>
                  <p>
                    <li>Differentiable ray-wave optical model for hybrid refractive-diffractive lens design.</li>
                  </p>
                </td>
              </tr>

              <!-- ============================================================================== -->
              <tr onmouseout="tasklens_stop()" onmouseover="tasklens_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='tasklens'><img src='images/tasklens2.png'></div>
                    <img src='images/tasklens1.png'>
                  </div>
                  <script type="text/javascript">
                    function tasklens_start() {
                      document.getElementById('tasklens').style.opacity = "1";
                    }

                    function tasklens_stop() {
                      document.getElementById('tasklens').style.opacity = "0";
                    }
                    tasklens_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2305.17185">
                    <papertitle>Task-Driven Lens Design for Image Classification</papertitle>
                  </a>
                  <br>
                  <b>Xinge Yang</b>, <a href="https://vccimaging.org/People/fuq/">Qiang Fu</a>, <a
                    href="https://www.b-phot.org/team/yunfeng-nie">Yunfeng Nie</a>, <a
                    href="https://vccimaging.org/People/heidriw/">Wolfgang Heidrich</a>
                  <br>
                  <em>arXiv prepint 2023.</b> <a href="https://arxiv.org/abs/2305.17185">Paper (arXiv)</a> / <a
                      href="papers/TaskLens.pdf">Paper (PDF)</a> / <a href="papers/TaskLens_supp.pdf">Supp
                      (PDF)</a></em>
                  <br>
                  <p></p>
                  <p>
                    <li>New lens design objective using a well-trained network to improve computer vision performance.</li>
                  </p>
                </td>
              </tr>

              <!-- ============================================================================== -->
              <tr onmouseout="aat_dff_stop()" onmouseover="aat_dff_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='aat_dff'><img src='images/aat_dff1.png'></div>
                    <img src='images/aat_dff2.png'>
                  </div>
                  <script type="text/javascript">
                    function aat_dff_start() {
                      document.getElementById('aat_dff').style.opacity = "1";
                    }

                    function aat_dff_stop() {
                      document.getElementById('aat_dff').style.opacity = "0";
                    }
                    aat_dff_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2303.04654">
                    <papertitle>Aberration-Aware Depth-from-Focus</papertitle>
                  </a>
                  <br>
                  <b>Xinge Yang</b>, <a href="https://vccimaging.org/People/fuq/">Qiang Fu</a>, <a
                    href="http://www.mohamed-elhoseiny.com/">Mohamed Elhoseiny</a>, <a
                    href="https://vccimaging.org/People/heidriw/">Wolfgang Heidrich</a>
                  <br>
                  <em>TPAMI & ICCP 2023.</b> <a href='https://ieeexplore.ieee.org/document/10209238'>Paper (IEEE)</a> /
                    <a href='papers/AberAwareDfF.pdf'>Paper (PDF)</a> / <a href='papers/AberAwareDfF_supp.pdf'>Supp
                      (PDF)</a> / <a href=https://vccimaging.org/Publications/Yang2023AATDfF>Project page</a> / <a
                      href=https://github.com/singer-yang/Aberration-Aware-Depth-from-Focus>Code</a></em>
                  <br>
                  <p></p>
                  <p>
                    <li>Neural PSF representation to accelerate synthetic dataset generation for depth estimation from defocus stacks.</li>
                  </p>
                </td>
              </tr>


              <!-- ============================================================================== -->
              <tr onmouseout="deeplens_stop()" onmouseover="deeplens_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='deeplens'><img src='images/deeplens2.jpg'></div>
                    <img src='images/deeplens1.jpg'>
                  </div>
                  <script type="text/javascript">
                    function deeplens_start() {
                      document.getElementById('deeplens').style.opacity = "1";
                    }
                    function deeplens_stop() {
                      document.getElementById('deeplens').style.opacity = "0";
                    }
                    deeplens_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2302.01089">
                    <papertitle>Curriculum Learning for ab initio Deep Learned Refractive Optics</papertitle>
                  </a>
                  <br>
                  <b>Xinge Yang</b>, <a href="https://vccimaging.org/People/fuq/">Qiang Fu</a>, <a
                    href="https://vccimaging.org/People/heidriw/">Wolfgang Heidrich</a>
                  <br>
                  <em>Nature Communications 2024.</b> <a href="https://www.nature.com/articles/s41467-024-50835-7">Paper
                      (Nature)</a> / <a href='papers/DeepLens.pdf'>Paper (PDF)</a> / <a
                      href='papers/DeepLens_supp.pdf'>Supp (PDF)</a> / <a
                      href=https://github.com/singer-yang/DeepLens>Code</a> / <a
                      href=https://youtu.be/32XuSyM-J-8>Video</a></em>
                  <br>
                  <p></p>
                  <p>
                    <li>Automated lens design from scratch with differentiable ray tracing and curriculum learning.</li>
                  </p>
                </td>
              </tr>

              <!-- Header for co-author papers -->
              <tr>
                <td style="padding-left:20px">
                  <p>Co-author papers:</p>
                </td>
              </tr>

              <!-- ============================================================================== -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/tolerance_lens.jpg'>
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2502.04719">
                    <papertitle>Tolerance-Aware Deep Optics</papertitle>
                  </a>
                  <br>
                  Jun Dai, Liqun Chen, <b>Xinge Yang</b>, Yuyao Hu, Jinwei Gu, Tianfan Xue
                  <br>
                  <em>arXiv prepint 2025.
                    <a href="https://arxiv.org/abs/2502.04719">Paper (arXiv)</a>
                    <a href="https://openimaginglab.github.io/LensTolerance/">Project page</a>
                  </em>
                  <br>
                  <p></p>
                  <p>
                    <li>Considering lens manufacturing tolerances in end-to-end lens design for better optical and computer vision robustness.</li>
                  </p>
                </td>
              </tr>

              <!-- ============================================================================== -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/fluidic_lens.jpg'>
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2406.00834">
                    <papertitle>End-to-end Optimization of Fluidic Lenses</papertitle>
                  </a>
                  <br>
                  Mulun Na, Hector Jimenez-Romero, <b>Xinge Yang</b>, Jonathan Klein, Dominik L. Michels, Wolfgang
                  Heidrich
                  <br>
                  <em>Siggraph Asia 2024.
                    <a href="https://computationalsciences.org/publications/na-2024-fluidic-lenses/na-2024-fluidic-lenses.pdf">Paper (PDF)</a>, 
                    <a href="https://computationalsciences.org/publications/na-2024-fluidic-lenses.html">Project page</a>
                  </em>
                  <br>
                  <p></p>
                  <p>
                    <li>Differentiable optimization of liquid surface shapes and manufacturing for rapid prototyping.</li>
                  </p>
                </td>
              </tr>

            </tbody>
          </table>

          <!-- Miscs ------------------------------------------------------------ -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Miscs</heading>
                  <p>
                    <li><b>More about me:</b> I like cats, photography, new techs, and most sports (especially
                      basketball and water sports). I lived in China, Singapore, Saudi Arabia, and the US, and want
                      to live in different places to experience the lifestyle of local people. I enjoy adventures
                      and challenges. I love my life.</li>
                    <br>
                    <li><b>Peer review statement:</b> I am pleased to be invited for peer review in my research
                      field. I will try my best to complete the review within two weeks. I apply the same high
                      standards to every paper, aiming for the utmost potential of the topic. However, I do not
                      expect the authors to address every suggestion I make and leave the final judgment to the
                      associate editor.</li>
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <!-- Miscs ------------------------------------------------------------ -->

          <!-- Footer ------------------------------------------------------------ -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="display:flex;justify-content:space-between;font-size:small;">
                    <span>Last updated: 10/21/2025</span>
                    <span>The website template is from <a href="https://jonbarron.info/">Dr. John Barron</a>.</span>
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <!-- Footer ------------------------------------------------------------ -->

        </td>
      </tr>
    </tbody>
  </table>
</body>

</html>